import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rcParams.update({
    'font.size': 18,
    'lines.linewidth': 3}
)

INVALID_RESULT = -1000

# ./results/pathfinder/
# BinaryClassifierResnet50_CurrentSubtractInhibitLayer_20200811_094315_no_max_pooling
# First  run of model without max pooling
model_ch_predicts = np.array([
    [6.263e-01, 6.187e-01, 6.152e-01, 6.165e-01, 6.114e-01, 6.102e-01],
    [7.282e-01, 7.186e-01, 7.136e-01, 7.014e-01, 6.912e-01, 6.935e-01],
    [8.988e-01, 8.857e-01, 8.729e-01, 8.631e-01, 8.588e-01, 8.272e-01],
    [8.639e-01, 8.514e-01, 8.429e-01, 8.299e-01, 8.290e-01, 8.256e-01],
    [6.711e-01, 6.615e-01, 6.378e-01, 6.213e-01, 6.076e-01, 6.003e-01],
    [9.723e-01, 9.649e-01, 9.601e-01, 9.548e-01, 9.520e-01, 9.470e-01],
    [8.127e-01, 8.070e-01, 7.948e-01, 7.890e-01, 7.823e-01, 7.753e-01],
    [7.806e-01, 7.685e-01, 7.584e-01, 7.506e-01, 7.412e-01, 7.333e-01],
    [6.581e-01, 6.487e-01, 6.405e-01, 6.301e-01, 6.349e-01, 6.253e-01],
    [7.544e-01, 7.310e-01, 7.038e-01, 6.723e-01, 6.500e-01, 6.447e-01],
    [5.389e-01, 5.350e-01, 5.233e-01, 5.069e-01, 4.873e-01, 4.831e-01],
    [6.233e-01, 6.084e-01, 6.003e-01, 5.984e-01, 5.901e-01, 5.755e-01],
    [9.715e-01, 9.636e-01, 9.572e-01, 9.440e-01, 9.392e-01, 9.226e-01],
    [6.730e-01, 6.607e-01, 6.547e-01, 6.480e-01, 6.413e-01, 6.291e-01],
    [9.283e-01, 9.220e-01, 9.116e-01, 9.071e-01, 8.979e-01, 8.827e-01],
    [7.471e-01, 7.310e-01, 7.166e-01, 6.990e-01, 6.976e-01, 6.805e-01],
    [9.381e-01, 9.203e-01, 9.013e-01, 8.819e-01, 8.634e-01, 8.463e-01],
    [6.855e-01, 6.730e-01, 6.650e-01, 6.472e-01, 6.483e-01, 6.384e-01],
    [5.882e-01, 5.850e-01, 5.794e-01, 5.786e-01, 5.803e-01, 5.773e-01],
    [8.989e-01, 8.958e-01, 8.890e-01, 8.824e-01, 8.750e-01, 8.714e-01],
    [6.698e-01, 6.548e-01, 6.252e-01, 6.215e-01, 6.070e-01, 5.891e-01],
    [5.943e-01, 5.793e-01, 5.762e-01, 5.661e-01, 5.673e-01, 5.593e-01],
    [7.324e-01, 7.172e-01, 6.922e-01, 6.772e-01, 6.538e-01, 6.499e-01],
    [-1.000e+03, -1.000e+03, -1.000e+03, -1.000e+03, -1.000e+03, -1.000e+03],
    [6.100e-01, 6.020e-01, 5.902e-01, 5.885e-01, 5.786e-01, 5.648e-01],
    [9.553e-01, 9.486e-01, 9.443e-01, 9.348e-01, 9.215e-01, 9.129e-01],
    [8.290e-01, 8.259e-01, 8.145e-01, 8.111e-01, 7.975e-01, 7.814e-01],
    [7.179e-01, 7.059e-01, 7.067e-01, 6.936e-01, 6.869e-01, 6.856e-01],
    [6.729e-01, 6.695e-01, 6.691e-01, 6.627e-01, 6.478e-01, 6.382e-01],
    [9.683e-01, 9.612e-01, 9.492e-01, 9.359e-01, 9.320e-01, 9.143e-01],
    [7.508e-01, 7.458e-01, 7.417e-01, 7.323e-01, 7.238e-01, 7.186e-01],
    [6.789e-01, 6.719e-01, 6.609e-01, 6.463e-01, 6.456e-01, 6.379e-01],
    [6.660e-01, 6.604e-01, 6.502e-01, 6.384e-01, 6.375e-01, 6.340e-01],
    [7.341e-01, 7.300e-01, 7.265e-01, 7.314e-01, 7.254e-01, 7.145e-01],
    [5.204e-01, 5.183e-01, 5.247e-01, 5.185e-01, 5.111e-01, 5.048e-01],
    [8.669e-01, 8.629e-01, 8.555e-01, 8.489e-01, 8.333e-01, 8.057e-01],
    [6.167e-01, 6.051e-01, 5.933e-01, 5.722e-01, 5.597e-01, 5.487e-01],
    [6.638e-01, 6.571e-01, 6.486e-01, 6.520e-01, 6.468e-01, 6.413e-01],
    [7.087e-01, 6.914e-01, 6.890e-01, 6.836e-01, 6.752e-01, 6.624e-01],
    [6.969e-01, 6.814e-01, 6.786e-01, 6.784e-01, 6.606e-01, 6.519e-01],
    [7.073e-01, 7.004e-01, 6.868e-01, 6.829e-01, 6.786e-01, 6.713e-01],
    [6.874e-01, 6.749e-01, 6.711e-01, 6.543e-01, 6.320e-01, 6.177e-01],
    [8.117e-01, 8.024e-01, 7.949e-01, 7.819e-01, 7.821e-01, 7.817e-01],
    [7.865e-01, 7.845e-01, 7.787e-01, 7.601e-01, 7.438e-01, 7.301e-01],
    [6.799e-01, 6.666e-01, 6.581e-01, 6.535e-01, 6.404e-01, 6.389e-01],
    [6.592e-01, 6.513e-01, 6.416e-01, 6.265e-01, 6.228e-01, 6.140e-01],
    [6.257e-01, 6.159e-01, 6.152e-01, 6.036e-01, 6.052e-01, 5.978e-01],
    [9.753e-01, 9.693e-01, 9.638e-01, 9.585e-01, 9.509e-01, 9.383e-01],
    [7.032e-01, 7.039e-01, 6.841e-01, 6.742e-01, 6.578e-01, 6.550e-01],
    [8.951e-01, 8.889e-01, 8.846e-01, 8.788e-01, 8.773e-01, 8.702e-01],
    [8.601e-01, 8.494e-01, 8.465e-01, 8.331e-01, 8.201e-01, 7.972e-01],
    [8.070e-01, 7.987e-01, 7.858e-01, 7.817e-01, 7.751e-01, 7.540e-01],
    [7.876e-01, 7.869e-01, 7.844e-01, 7.766e-01, 7.619e-01, 7.554e-01],
    [6.951e-01, 6.911e-01, 6.777e-01, 6.765e-01, 6.810e-01, 6.766e-01],
    [9.411e-01, 9.358e-01, 9.282e-01, 9.037e-01, 8.933e-01, 8.769e-01],
    [6.062e-01, 5.952e-01, 5.891e-01, 5.848e-01, 5.759e-01, 5.749e-01],
    [2.942e-01, 3.240e-01, 2.734e-01, 3.125e-01, 3.185e-01, 3.058e-01],
    [6.097e-01, 6.017e-01, 5.953e-01, 5.893e-01, 5.895e-01, 5.763e-01],
    [9.135e-01, 9.067e-01, 8.969e-01, 8.860e-01, 8.675e-01, 8.543e-01],
    [5.666e-01, 5.781e-01, 5.771e-01, 5.806e-01, 5.815e-01, 5.863e-01],
    [7.234e-01, 7.113e-01, 6.927e-01, 6.855e-01, 6.746e-01, 6.669e-01],
    [7.400e-01, 7.288e-01, 7.157e-01, 7.057e-01, 7.031e-01, 6.918e-01],
    [6.924e-01, 6.882e-01, 6.736e-01, 6.851e-01, 6.816e-01, 6.648e-01],
    [6.882e-01, 6.821e-01, 6.771e-01, 6.770e-01, 6.777e-01, 6.694e-01]])

model_ch_outs = np.array([
    [2.612e+00, 2.397e+00, 2.239e+00, 2.343e+00, 2.361e+00, 2.417e+00],
    [2.051e+00, 1.962e+00, 1.823e+00, 1.761e+00, 1.630e+00, 1.551e+00],
    [1.270e+02, 1.232e+02, 1.181e+02, 1.143e+02, 1.111e+02, 1.022e+02],
    [7.426e+00, 7.394e+00, 7.357e+00, 7.348e+00, 7.324e+00, 7.287e+00],
    [1.231e+01, 1.233e+01, 1.238e+01, 1.235e+01, 1.232e+01, 1.217e+01],
    [1.309e+02, 1.279e+02, 1.244e+02, 1.211e+02, 1.172e+02, 1.143e+02],
    [7.784e+00, 7.715e+00, 7.650e+00, 7.564e+00, 7.559e+00, 7.517e+00],
    [6.597e+00, 6.642e+00, 6.629e+00, 6.633e+00, 6.634e+00, 6.648e+00],
    [8.175e+00, 8.185e+00, 8.148e+00, 8.161e+00, 8.151e+00, 8.063e+00],
    [3.466e+01, 3.404e+01, 3.264e+01, 3.159e+01, 3.085e+01, 3.012e+01],
    [7.690e+01, 7.325e+01, 6.993e+01, 6.576e+01, 6.240e+01, 5.672e+01],
    [8.608e-01, 8.613e-01, 8.557e-01, 8.535e-01, 8.477e-01, 8.262e-01],
    [9.136e+01, 8.813e+01, 8.445e+01, 8.104e+01, 7.928e+01, 7.552e+01],
    [5.731e+01, 5.454e+01, 5.325e+01, 5.153e+01, 4.885e+01, 4.452e+01],
    [7.759e+01, 7.626e+01, 7.436e+01, 7.291e+01, 7.112e+01, 6.903e+01],
    [4.879e+01, 4.749e+01, 4.437e+01, 4.169e+01, 3.984e+01, 3.777e+01],
    [1.041e+02, 1.000e+02, 9.636e+01, 9.330e+01, 8.981e+01, 8.782e+01],
    [8.567e+00, 8.538e+00, 8.457e+00, 8.403e+00, 8.478e+00, 8.199e+00],
    [6.377e+00, 6.129e+00, 5.952e+00, 5.931e+00, 5.933e+00, 5.878e+00],
    [5.013e+01, 4.915e+01, 4.743e+01, 4.694e+01, 4.667e+01, 4.473e+01],
    [1.358e+01, 1.358e+01, 1.358e+01, 1.356e+01, 1.359e+01, 1.361e+01],
    [5.538e+00, 5.405e+00, 5.327e+00, 5.212e+00, 5.128e+00, 5.098e+00],
    [1.274e+01, 1.276e+01, 1.273e+01, 1.272e+01, 1.263e+01, 1.261e+01],
    [-1.000e+03, -1.000e+03, -1.000e+03, -1.000e+03, -1.000e+03, -1.000e+03],
    [7.027e+00, 6.918e+00, 6.717e+00, 6.631e+00, 6.422e+00, 6.193e+00],
    [8.201e+01, 7.885e+01, 7.570e+01, 7.176e+01, 6.756e+01, 6.377e+01],
    [6.782e+01, 6.579e+01, 6.287e+01, 6.125e+01, 5.910e+01, 5.601e+01],
    [3.480e+01, 3.423e+01, 3.387e+01, 3.318e+01, 3.268e+01, 3.153e+01],
    [8.697e+01, 8.356e+01, 8.207e+01, 7.817e+01, 7.419e+01, 6.915e+01],
    [1.146e+02, 1.098e+02, 1.046e+02, 1.003e+02, 9.628e+01, 9.095e+01],
    [6.946e+01, 6.685e+01, 6.651e+01, 6.315e+01, 5.839e+01, 5.302e+01],
    [5.097e+01, 4.977e+01, 4.866e+01, 4.848e+01, 4.749e+01, 4.698e+01],
    [3.406e-01, 3.149e-01, 2.637e-01, 2.588e-01, 2.457e-01, 2.281e-01],
    [5.723e+01, 5.533e+01, 5.267e+01, 5.027e+01, 4.800e+01, 4.625e+01],
    [2.153e+01, 2.155e+01, 2.220e+01, 2.286e+01, 2.288e+01, 2.159e+01],
    [8.148e+01, 7.864e+01, 7.582e+01, 7.242e+01, 7.096e+01, 6.856e+01],
    [7.672e+00, 7.654e+00, 7.620e+00, 7.606e+00, 7.573e+00, 7.512e+00],
    [6.518e+00, 6.210e+00, 5.975e+00, 5.928e+00, 5.903e+00, 5.837e+00],
    [4.374e+01, 4.145e+01, 3.964e+01, 3.650e+01, 3.396e+01, 3.201e+01],
    [1.066e+01, 1.065e+01, 1.051e+01, 1.050e+01, 1.040e+01, 1.021e+01],
    [9.982e-01, 9.699e-01, 9.668e-01, 9.697e-01, 9.381e-01, 9.237e-01],
    [4.137e+00, 4.092e+00, 3.987e+00, 3.895e+00, 3.898e+00, 3.879e+00],
    [1.079e+00, 1.062e+00, 1.076e+00, 1.073e+00, 1.072e+00, 1.068e+00],
    [6.951e+01, 6.577e+01, 6.094e+01, 5.657e+01, 5.302e+01, 4.922e+01],
    [7.131e-01, 7.030e-01, 6.892e-01, 6.667e-01, 6.512e-01, 6.279e-01],
    [6.898e+00, 6.823e+00, 6.724e+00, 6.668e+00, 6.654e+00, 6.645e+00],
    [9.642e+00, 9.657e+00, 9.650e+00, 9.675e+00, 9.679e+00, 9.581e+00],
    [8.356e+01, 8.086e+01, 7.787e+01, 7.428e+01, 7.127e+01, 6.808e+01],
    [2.537e-01, 1.727e-01, 1.348e-01, 1.381e-01, 1.150e-01, 9.927e-02],
    [6.704e+01, 6.539e+01, 6.343e+01, 6.131e+01, 6.080e+01, 5.926e+01],
    [5.261e+01, 5.178e+01, 5.017e+01, 4.932e+01, 4.800e+01, 4.670e+01],
    [9.867e+01, 9.448e+01, 9.299e+01, 8.965e+01, 8.529e+01, 7.882e+01],
    [7.303e-01, 7.257e-01, 7.081e-01, 6.916e-01, 6.876e-01, 6.710e-01],
    [6.792e+00, 6.731e+00, 6.649e+00, 6.648e+00, 6.649e+00, 6.596e+00],
    [7.903e+01, 7.698e+01, 7.496e+01, 7.188e+01, 7.042e+01, 6.799e+01],
    [5.614e+00, 5.583e+00, 5.535e+00, 5.520e+00, 5.500e+00, 5.463e+00],
    [2.252e-02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],
    [1.541e+00, 1.517e+00, 1.507e+00, 1.510e+00, 1.492e+00, 1.465e+00],
    [7.543e+01, 7.290e+01, 6.909e+01, 6.655e+01, 6.362e+01, 6.100e+01],
    [3.498e-02, 1.667e-02, 1.959e-02, 2.003e-02, 1.929e-02, 8.201e-03],
    [7.435e+00, 7.398e+00, 7.375e+00, 7.375e+00, 7.363e+00, 7.338e+00],
    [6.196e+00, 6.159e+00, 6.126e+00, 6.117e+00, 6.140e+00, 6.155e+00],
    [2.042e+00, 2.039e+00, 2.035e+00, 2.034e+00, 2.032e+00, 2.026e+00],
    [5.292e+00, 5.275e+00, 5.193e+00, 5.132e+00, 5.087e+00, 4.995e+00]])


# ---------------------------------------------------------------------------------------
# ./results/pathfinder/BinaryClassifierResnet50_ControlMatchParametersLayer_20200826_231032_no_max_pooling
control_ch_predicts = np.array([
    [0.539, 0.541, 0.540, 0.547, 0.543, 0.538],
    [0.571, 0.570, 0.566, 0.567, 0.566, 0.565],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.584, 0.584, 0.583, 0.589, 0.587, 0.588],
    [0.535, 0.532, 0.528, 0.523, 0.523, 0.517],
    [0.714, 0.707, 0.7, 0.695, 0.694, 0.687],
    [0.468, 0.46, 0.459, 0.452, 0.45, 0.439],
    [0.816, 0.809, 0.808, 0.806, 0.805, 0.804],
    [0.644, 0.638, 0.634, 0.63, 0.629, 0.623],
    [0.548, 0.545, 0.548, 0.547, 0.542, 0.549],
    [0.655, 0.653, 0.646, 0.646, 0.643, 0.639],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.531, 0.527, 0.528, 0.524, 0.526, 0.525],
    [0.697, 0.693, 0.694, 0.691, 0.69, 0.683],
    [0.754, 0.752, 0.754, 0.75, 0.748, 0.749],
    [0.639, 0.637, 0.631, 0.64, 0.638, 0.635],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.489, 0.49, 0.488, 0.488, 0.49, 0.488],
    [0.591, 0.593, 0.589, 0.594, 0.584, 0.579],
    [0.673, 0.67, 0.67, 0.671, 0.664, 0.658],
    [0.865, 0.862, 0.861, 0.857, 0.856, 0.855],
    [0.842, 0.836, 0.828, 0.821, 0.812, 0.805],
    [0.553, 0.556, 0.554, 0.557, 0.547, 0.55],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.626, 0.629, 0.624, 0.626, 0.628, 0.63],
    [0.489, 0.489, 0.494, 0.492, 0.49, 0.491],
    [0.573, 0.573, 0.576, 0.57, 0.575, 0.58],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.798, 0.8, 0.8, 0.798, 0.8, 0.802],
    [0.858, 0.855, 0.852, 0.851, 0.846, 0.844],
    [0.48, 0.48, 0.475, 0.473, 0.465, 0.467],
    [0.704, 0.7, 0.698, 0.7, 0.697, 0.7],
    [0.809, 0.81, 0.819, 0.809, 0.806, 0.817],
    [0.837, 0.835, 0.834, 0.836, 0.835, 0.833],
    [0.801, 0.796, 0.787, 0.778, 0.776, 0.772],
    [0.724, 0.721, 0.719, 0.713, 0.71, 0.708],
    [0.681, 0.676, 0.676, 0.67, 0.668, 0.663],
    [0.561, 0.557, 0.555, 0.551, 0.546, 0.54],
    [0.783, 0.782, 0.779, 0.771, 0.761, 0.752],
    [0.549, 0.54, 0.532, 0.527, 0.524, 0.52],
    [0.491, 0.492, 0.492, 0.487, 0.484, 0.473],
    [0.599, 0.593, 0.584, 0.591, 0.614, 0.59],
    [0.457, 0.445, 0.443, 0.435, 0.426, 0.417],
    [0.701, 0.695, 0.693, 0.692, 0.685, 0.691],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.711, 0.708, 0.705, 0.706, 0.705, 0.694],
    [0.582, 0.58, 0.584, 0.582, 0.581, 0.58],
    [0.594, 0.589, 0.594, 0.588, 0.598, 0.598],
    [0.619, 0.616, 0.609, 0.609, 0.606, 0.611],
    [0.5, 0.502, 0.5, 0.496, 0.495, 0.489],
    [0.552, 0.555, 0.553, 0.552, 0.554, 0.55],
    [0.819, 0.815, 0.812, 0.814, 0.807, 0.805],
    [0.629, 0.623, 0.623, 0.625, 0.629, 0.624],
    [0.574, 0.57, 0.566, 0.565, 0.566, 0.566],
    [0.609, 0.609, 0.599, 0.606, 0.597, 0.599],
    [0.712, 0.707, 0.7, 0.695, 0.691, 0.686],
    [0.777, 0.775, 0.773, 0.775, 0.772, 0.767],
    [0.648, 0.616, 0.611, 0.622, 0.624, 0.624],
    [0.846, 0.841, 0.835, 0.829, 0.821, 0.815],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.853, 0.846, 0.848, 0.849, 0.847, 0.843],
    [0.485, 0.479, 0.474, 0.468, 0.462, 0.452],
    [0.578, 0.572, 0.569, 0.565, 0.558, 0.561]])

control_ch_outs = np.array([
    [0.033, 0.032, 0.028, 0.028, 0.024, 0.022],
    [0.311, 0.311, 0.309, 0.309, 0.303, 0.3],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.94, 0.925, 0.891, 0.853, 0.811, 0.784],
    [0.085, 0.083, 0.076, 0.073, 0.066, 0.062],
    [0.606, 0.598, 0.59, 0.584, 0.579, 0.576],
    [0.218, 0.221, 0.222, 0.223, 0.223, 0.225],
    [0.621, 0.615, 0.611, 0.604, 0.597, 0.597],
    [0.42, 0.415, 0.409, 0.406, 0.402, 0.394],
    [0.857, 0.846, 0.827, 0.795, 0.772, 0.758],
    [0.485, 0.479, 0.472, 0.467, 0.458, 0.457],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.27, 0.273, 0.276, 0.278, 0.277, 0.276],
    [0.435, 0.429, 0.423, 0.416, 0.413, 0.405],
    [0.528, 0.524, 0.518, 0.51, 0.507, 0.503],
    [0.026, 0.021, 0.015, 0.01, 0.008, 0.005],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.73, 0.715, 0.689, 0.648, 0.624, 0.587],
    [0.18, 0.178, 0.18, 0.179, 0.18, 0.182],
    [0.403, 0.399, 0.395, 0.391, 0.393, 0.383],
    [0.86, 0.857, 0.859, 0.861, 0.857, 0.859],
    [0.601, 0.592, 0.578, 0.56, 0.541, 0.526],
    [0.581, 0.57, 0.561, 0.541, 0.52, 0.493],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.159, 0.151, 0.143, 0.131, 0.123, 0.113],
    [0.304, 0.312, 0.32, 0.326, 0.325, 0.323],
    [0.552, 0.541, 0.528, 0.531, 0.516, 0.489],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.63, 0.627, 0.624, 0.618, 0.614, 0.612],
    [1.183, 1.181, 1.177, 1.166, 1.152, 1.143],
    [0.186, 0.188, 0.184, 0.182, 0.18, 0.181],
    [0.572, 0.564, 0.571, 0.573, 0.587, 0.578],
    [0.795, 0.803, 0.81, 0.787, 0.768, 0.772],
    [1.128, 1.125, 1.117, 1.104, 1.097, 1.104],
    [0.687, 0.68, 0.669, 0.651, 0.644, 0.638],
    [0.608, 0.603, 0.621, 0.605, 0.602, 0.602],
    [1.359, 1.358, 1.343, 1.344, 1.337, 1.318],
    [0.523, 0.519, 0.51, 0.506, 0.493, 0.484],
    [0.556, 0.549, 0.546, 0.546, 0.541, 0.543],
    [0.643, 0.637, 0.633, 0.628, 0.627, 0.627],
    [0.191, 0.191, 0.194, 0.187, 0.184, 0.177],
    [0.001, 0.002, 0.001, 0., 0., 0.],
    [1.473, 1.482, 1.488, 1.481, 1.49, 1.479],
    [0.847, 0.827, 0.824, 0.824, 0.816, 0.814],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.627, 0.612, 0.606, 0.602, 0.598, 0.57],
    [0.666, 0.664, 0.652, 0.638, 0.622, 0.603],
    [0.074, 0.061, 0.053, 0.048, 0.039, 0.03],
    [2.709, 2.673, 2.64, 2.613, 2.572, 2.515],
    [0.191, 0.19, 0.186, 0.184, 0.178, 0.178],
    [0.298, 0.293, 0.287, 0.286, 0.28, 0.282],
    [0.903, 0.899, 0.899, 0.888, 0.882, 0.885],
    [0.312, 0.312, 0.306, 0.295, 0.287, 0.285],
    [0.493, 0.485, 0.475, 0.465, 0.448, 0.44],
    [0.271, 0.265, 0.264, 0.259, 0.248, 0.241],
    [3.692, 3.658, 3.614, 3.575, 3.555, 3.511],
    [0.859, 0.846, 0.832, 0.819, 0.815, 0.791],
    [0.007, 0.004, 0.007, 0.008, 0.01, 0.003],
    [0.458, 0.451, 0.441, 0.433, 0.424, 0.415],
    [-1000., -1000., -1000., -1000., -1000., -1000.],
    [0.922, 0.912, 0.905, 0.893, 0.891, 0.878],
    [0.34, 0.34, 0.337, 0.337, 0.335, 0.331],
    [0.574, 0.581, 0.584, 0.586, 0.584, 0.579]])

# --------------------------------------------------------------------------------------


def get_pop_mean_std(in_arr):
    valid_idxs = \
        [idx for idx, ch_resp in enumerate(in_arr) if ch_resp[0] != INVALID_RESULT]

    filtered_in_arr = in_arr[valid_idxs, ]
    mean_in_arr = np.mean(filtered_in_arr, axis=0)
    std_in_arr = np.std(filtered_in_arr, axis=0)
    n_ch = len(valid_idxs)

    return mean_in_arr, std_in_arr, n_ch


def get_pop_mean_std_oo_gain(out_arr, epsilon=1e-4):
    """ gain = output multiple RCD, output rcd=1 (first column)"""
    valid_idxs = \
        [idx for idx, ch_resp in enumerate(out_arr) if ch_resp[0] != INVALID_RESULT]

    filtered_out_arr = out_arr[valid_idxs, ]
    noise_resp_arr = np.expand_dims(filtered_out_arr[:, 0], axis=1)

    gains = filtered_out_arr / (noise_resp_arr + epsilon)

    mean_gains = np.mean(gains, axis=0)
    std_gains = np.std(gains, axis=0)
    n_ch = len(valid_idxs)

    return mean_gains, std_gains, n_ch


def get_gradients_of_linear_fits(x, out_arr):
    out_acts_gradients = []

    for ch_idx in range(len(out_arr)):

        if out_arr[ch_idx, 0] != INVALID_RESULT:
            out_acts = out_arr[ch_idx, ]
            m_out, b_out = np.polyfit(x, out_acts, deg=1)

            out_acts_gradients.append(m_out)

    return out_acts_gradients


if __name__ == '__main__':
    plt.ion()

    frag_tile_size = np.array([7, 7])
    bubble_tile_sizes = np.array([[7, 7], [9, 9], [11, 11], [13, 13], [15, 15], [17, 17]])

    # Relative co-linear distance =  spacing / fragment length
    rcd = bubble_tile_sizes[:, 0] / np.float(frag_tile_size[0])

    fig = plt.figure(constrained_layout=True, figsize=(12, 9))
    gs = fig.add_gridspec(3, 4)

    # Predictions vs Length
    # ---------------------
    ax1 = fig.add_subplot(gs[0, 0])
    # ax1.set_yticks([0, 0.5, 1])
    ax1.set_ylabel('Prediction')
    ax1.set_xlabel("Length")

    # Predictions vs Spacing
    # ----------------------
    mean_model_predicts, std_model_predicts, model_n_avg = get_pop_mean_std(model_ch_predicts)
    mean_control_predicts, std_control_predicts, control_n_avg = get_pop_mean_std(control_ch_predicts)

    ax2 = fig.add_subplot(gs[0, 1], sharey=ax1)
    ax2.plot(rcd, mean_model_predicts, label='Model (N={})'.format(model_n_avg), color='b')
    ax2.fill_between(
        rcd,
        mean_model_predicts - std_model_predicts,
        mean_model_predicts + std_model_predicts,
        alpha=0.2, color='b')
    ax2.plot(rcd, mean_control_predicts, label='Control (N={})'.format(control_n_avg), color='r')
    ax2.fill_between(
        rcd,
        mean_control_predicts - std_control_predicts,
        mean_control_predicts + std_control_predicts,
        alpha=0.2, color='r')

    ax2.set_xlabel("RCD")
    # ax2.legend()
    # ax2.set_ylabel("Prediction")
    # ax2.set_yticks([0, 0.5, 1])

    # Gain vs Length
    # ----------------
    ax3 = fig.add_subplot(gs[0, 2])
    ax3.set_ylabel('Gain')
    ax3.set_xlabel("Length")

    # Gain vs Spacing
    # ----------------
    mean_model_gains, std_model_gains, model_n_avg = get_pop_mean_std_oo_gain(model_ch_outs)
    mean_control_gains, std_control_gains, control_n_avg = get_pop_mean_std_oo_gain(control_ch_outs)

    ax4 = fig.add_subplot(gs[0, 3], sharey=ax3)

    ax4.plot(rcd, mean_model_gains, label='Model (N={})'.format(model_n_avg), color='b')
    ax4.fill_between(
        rcd,
        mean_model_gains - std_model_gains,
        mean_model_gains + std_model_gains,
        alpha=0.2, color='b')
    ax4.plot(rcd, mean_control_gains, label='Control (N={})'.format(control_n_avg), color='r')
    ax4.fill_between(
        rcd,
        mean_control_gains - std_control_gains,
        mean_control_gains + std_control_gains,
        alpha=0.2, color='r')

    ax4.set_xlabel("RCD")
    # ax4.set_ylabel("Gain")
    # ax2.legend()

    # ----------------------------------------------------------------------------------
    # histogram Gain vs Length - Model
    ax5 = fig.add_subplot(gs[1, 0:2])
    ax5.set_ylabel("Freq")

    # histogram Gain Vs length - Control
    ax6 = fig.add_subplot(gs[2, 0:2], sharex=ax5)
    ax6.set_xlabel("Gradient Linear Fit - Gain vs Length")
    ax6.set_ylabel("Freq")

    # histogram Gain Vs Spacing - Model
    model_m = get_gradients_of_linear_fits(rcd, model_ch_outs)

    ax7 = fig.add_subplot(gs[1, 2:4], sharey=ax5)
    ax7.hist(model_m, label="Model (N={})".format(model_n_avg))
    ax7.legend()

    # histogram Gain Vs Spacing - control
    control_m = get_gradients_of_linear_fits(rcd, control_ch_outs)

    ax8 = fig.add_subplot(gs[2, 2:4], sharey=ax6, sharex=ax7)
    ax8.hist(control_m, label="control (N={})".format(control_n_avg), color='r')
    ax8.set_xlabel("Gradient Linear Fit - Gain vs Spacing")
    ax8.legend()

    # -----------------------------------------------------------------------------------
    print('End')
    import pdb

    pdb.set_trace()
